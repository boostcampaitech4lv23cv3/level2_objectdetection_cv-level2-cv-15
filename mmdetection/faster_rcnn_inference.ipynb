{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fd75793",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/detection/lib/python3.7/site-packages/mmcv/__init__.py:21: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  'On January 1, 2023, MMCV will release v2.0.0, in which it will remove '\n"
     ]
    }
   ],
   "source": [
    "import mmcv\n",
    "from mmcv import Config\n",
    "from mmdet.datasets import (build_dataloader, build_dataset,\n",
    "                            replace_ImageToTensor)\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import single_gpu_test\n",
    "from mmcv.runner import load_checkpoint\n",
    "import os\n",
    "from mmcv.parallel import MMDataParallel\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edda58ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = (\"General trash\", \"Paper\", \"Paper pack\", \"Metal\", \"Glass\", \n",
    "           \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\")\n",
    "\n",
    "# config file 들고오기\n",
    "cfg = Config.fromfile('/opt/ml/level2_objectdetection_cv-level2-cv-15/mmdetection/configs/_syh_/5_CascadeRCNN_SwinL_FPN/run.py')\n",
    "\n",
    "root='/opt/ml/dataset/'\n",
    "\n",
    "epoch = 'best_bbox_mAP_50_epoch_19'\n",
    "\n",
    "# dataset config 수정\n",
    "cfg.data.test.classes = classes\n",
    "cfg.data.test.img_prefix = root\n",
    "cfg.data.test.ann_file = root + 'test.json'\n",
    "cfg.data.test.pipeline[1]['img_scale'] = (1024,1024) # Resize\n",
    "cfg.data.test.test_mode = True\n",
    "\n",
    "cfg.data.samples_per_gpu = 4\n",
    "\n",
    "cfg.seed=42\n",
    "cfg.gpu_ids = [1]\n",
    "cfg.work_dir = './work_dirs/run'\n",
    "\n",
    "# print(type(cfg.model.roi_head.bbox_head))\n",
    "# cfg.model.roi_head.bbox_head.num_classes = 10\n",
    "for bbox_head in cfg.model.roi_head.bbox_head:\n",
    "    bbox_head.num_classes = 10 \n",
    "\n",
    "cfg.optimizer_config.grad_clip = dict(max_norm=35, norm_type=2)\n",
    "cfg.model.train_cfg = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b086a8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# build dataset & dataloader\n",
    "dataset = build_dataset(cfg.data.test)\n",
    "data_loader = build_dataloader(\n",
    "        dataset,\n",
    "        samples_per_gpu=1,\n",
    "        workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "        dist=False,\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83b3eae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: ./work_dirs/run/best_bbox_mAP_50_epoch_19.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for backbone.patch_embed.projection.weight: copying a param with shape torch.Size([96, 3, 4, 4]) from checkpoint, the shape in current model is torch.Size([192, 3, 4, 4]).\n",
      "size mismatch for backbone.patch_embed.projection.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.patch_embed.norm.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.patch_embed.norm.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stages.0.blocks.0.norm1.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stages.0.blocks.0.norm1.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table: copying a param with shape torch.Size([169, 3]) from checkpoint, the shape in current model is torch.Size([169, 6]).\n",
      "size mismatch for backbone.stages.0.blocks.0.attn.w_msa.qkv.weight: copying a param with shape torch.Size([288, 96]) from checkpoint, the shape in current model is torch.Size([576, 192]).\n",
      "size mismatch for backbone.stages.0.blocks.0.attn.w_msa.qkv.bias: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([576]).\n",
      "size mismatch for backbone.stages.0.blocks.0.attn.w_msa.proj.weight: copying a param with shape torch.Size([96, 96]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n",
      "size mismatch for backbone.stages.0.blocks.0.attn.w_msa.proj.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stages.0.blocks.0.norm2.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stages.0.blocks.0.norm2.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stages.0.blocks.0.ffn.layers.0.0.weight: copying a param with shape torch.Size([384, 96]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n",
      "size mismatch for backbone.stages.0.blocks.0.ffn.layers.0.0.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.0.blocks.0.ffn.layers.1.weight: copying a param with shape torch.Size([96, 384]) from checkpoint, the shape in current model is torch.Size([192, 768]).\n",
      "size mismatch for backbone.stages.0.blocks.0.ffn.layers.1.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stages.0.blocks.1.norm1.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stages.0.blocks.1.norm1.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table: copying a param with shape torch.Size([169, 3]) from checkpoint, the shape in current model is torch.Size([169, 6]).\n",
      "size mismatch for backbone.stages.0.blocks.1.attn.w_msa.qkv.weight: copying a param with shape torch.Size([288, 96]) from checkpoint, the shape in current model is torch.Size([576, 192]).\n",
      "size mismatch for backbone.stages.0.blocks.1.attn.w_msa.qkv.bias: copying a param with shape torch.Size([288]) from checkpoint, the shape in current model is torch.Size([576]).\n",
      "size mismatch for backbone.stages.0.blocks.1.attn.w_msa.proj.weight: copying a param with shape torch.Size([96, 96]) from checkpoint, the shape in current model is torch.Size([192, 192]).\n",
      "size mismatch for backbone.stages.0.blocks.1.attn.w_msa.proj.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stages.0.blocks.1.norm2.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stages.0.blocks.1.norm2.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stages.0.blocks.1.ffn.layers.0.0.weight: copying a param with shape torch.Size([384, 96]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n",
      "size mismatch for backbone.stages.0.blocks.1.ffn.layers.0.0.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.0.blocks.1.ffn.layers.1.weight: copying a param with shape torch.Size([96, 384]) from checkpoint, the shape in current model is torch.Size([192, 768]).\n",
      "size mismatch for backbone.stages.0.blocks.1.ffn.layers.1.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.stages.0.downsample.norm.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.0.downsample.norm.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.0.downsample.reduction.weight: copying a param with shape torch.Size([192, 384]) from checkpoint, the shape in current model is torch.Size([384, 768]).\n",
      "size mismatch for backbone.stages.1.blocks.0.norm1.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stages.1.blocks.0.norm1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table: copying a param with shape torch.Size([169, 6]) from checkpoint, the shape in current model is torch.Size([169, 12]).\n",
      "size mismatch for backbone.stages.1.blocks.0.attn.w_msa.qkv.weight: copying a param with shape torch.Size([576, 192]) from checkpoint, the shape in current model is torch.Size([1152, 384]).\n",
      "size mismatch for backbone.stages.1.blocks.0.attn.w_msa.qkv.bias: copying a param with shape torch.Size([576]) from checkpoint, the shape in current model is torch.Size([1152]).\n",
      "size mismatch for backbone.stages.1.blocks.0.attn.w_msa.proj.weight: copying a param with shape torch.Size([192, 192]) from checkpoint, the shape in current model is torch.Size([384, 384]).\n",
      "size mismatch for backbone.stages.1.blocks.0.attn.w_msa.proj.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stages.1.blocks.0.norm2.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stages.1.blocks.0.norm2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stages.1.blocks.0.ffn.layers.0.0.weight: copying a param with shape torch.Size([768, 192]) from checkpoint, the shape in current model is torch.Size([1536, 384]).\n",
      "size mismatch for backbone.stages.1.blocks.0.ffn.layers.0.0.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "size mismatch for backbone.stages.1.blocks.0.ffn.layers.1.weight: copying a param with shape torch.Size([192, 768]) from checkpoint, the shape in current model is torch.Size([384, 1536]).\n",
      "size mismatch for backbone.stages.1.blocks.0.ffn.layers.1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stages.1.blocks.1.norm1.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stages.1.blocks.1.norm1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table: copying a param with shape torch.Size([169, 6]) from checkpoint, the shape in current model is torch.Size([169, 12]).\n",
      "size mismatch for backbone.stages.1.blocks.1.attn.w_msa.qkv.weight: copying a param with shape torch.Size([576, 192]) from checkpoint, the shape in current model is torch.Size([1152, 384]).\n",
      "size mismatch for backbone.stages.1.blocks.1.attn.w_msa.qkv.bias: copying a param with shape torch.Size([576]) from checkpoint, the shape in current model is torch.Size([1152]).\n",
      "size mismatch for backbone.stages.1.blocks.1.attn.w_msa.proj.weight: copying a param with shape torch.Size([192, 192]) from checkpoint, the shape in current model is torch.Size([384, 384]).\n",
      "size mismatch for backbone.stages.1.blocks.1.attn.w_msa.proj.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stages.1.blocks.1.norm2.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stages.1.blocks.1.norm2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stages.1.blocks.1.ffn.layers.0.0.weight: copying a param with shape torch.Size([768, 192]) from checkpoint, the shape in current model is torch.Size([1536, 384]).\n",
      "size mismatch for backbone.stages.1.blocks.1.ffn.layers.0.0.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "size mismatch for backbone.stages.1.blocks.1.ffn.layers.1.weight: copying a param with shape torch.Size([192, 768]) from checkpoint, the shape in current model is torch.Size([384, 1536]).\n",
      "size mismatch for backbone.stages.1.blocks.1.ffn.layers.1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.stages.1.downsample.norm.weight: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "size mismatch for backbone.stages.1.downsample.norm.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "size mismatch for backbone.stages.1.downsample.reduction.weight: copying a param with shape torch.Size([384, 768]) from checkpoint, the shape in current model is torch.Size([768, 1536]).\n",
      "size mismatch for backbone.stages.2.blocks.0.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.0.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table: copying a param with shape torch.Size([169, 12]) from checkpoint, the shape in current model is torch.Size([169, 24]).\n",
      "size mismatch for backbone.stages.2.blocks.0.attn.w_msa.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.0.attn.w_msa.qkv.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([2304]).\n",
      "size mismatch for backbone.stages.2.blocks.0.attn.w_msa.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.0.attn.w_msa.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.0.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.0.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.0.ffn.layers.0.0.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([3072, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.0.ffn.layers.0.0.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "size mismatch for backbone.stages.2.blocks.0.ffn.layers.1.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 3072]).\n",
      "size mismatch for backbone.stages.2.blocks.0.ffn.layers.1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.1.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.1.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table: copying a param with shape torch.Size([169, 12]) from checkpoint, the shape in current model is torch.Size([169, 24]).\n",
      "size mismatch for backbone.stages.2.blocks.1.attn.w_msa.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.1.attn.w_msa.qkv.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([2304]).\n",
      "size mismatch for backbone.stages.2.blocks.1.attn.w_msa.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.1.attn.w_msa.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.1.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.1.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.1.ffn.layers.0.0.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([3072, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.1.ffn.layers.0.0.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "size mismatch for backbone.stages.2.blocks.1.ffn.layers.1.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 3072]).\n",
      "size mismatch for backbone.stages.2.blocks.1.ffn.layers.1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.2.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.2.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table: copying a param with shape torch.Size([169, 12]) from checkpoint, the shape in current model is torch.Size([169, 24]).\n",
      "size mismatch for backbone.stages.2.blocks.2.attn.w_msa.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.2.attn.w_msa.qkv.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([2304]).\n",
      "size mismatch for backbone.stages.2.blocks.2.attn.w_msa.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.2.attn.w_msa.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.2.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.2.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.2.ffn.layers.0.0.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([3072, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.2.ffn.layers.0.0.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "size mismatch for backbone.stages.2.blocks.2.ffn.layers.1.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 3072]).\n",
      "size mismatch for backbone.stages.2.blocks.2.ffn.layers.1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.3.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.3.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table: copying a param with shape torch.Size([169, 12]) from checkpoint, the shape in current model is torch.Size([169, 24]).\n",
      "size mismatch for backbone.stages.2.blocks.3.attn.w_msa.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.3.attn.w_msa.qkv.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([2304]).\n",
      "size mismatch for backbone.stages.2.blocks.3.attn.w_msa.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.3.attn.w_msa.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.3.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.3.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.3.ffn.layers.0.0.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([3072, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.3.ffn.layers.0.0.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "size mismatch for backbone.stages.2.blocks.3.ffn.layers.1.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 3072]).\n",
      "size mismatch for backbone.stages.2.blocks.3.ffn.layers.1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.4.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.4.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table: copying a param with shape torch.Size([169, 12]) from checkpoint, the shape in current model is torch.Size([169, 24]).\n",
      "size mismatch for backbone.stages.2.blocks.4.attn.w_msa.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.4.attn.w_msa.qkv.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([2304]).\n",
      "size mismatch for backbone.stages.2.blocks.4.attn.w_msa.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.4.attn.w_msa.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.4.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.4.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.4.ffn.layers.0.0.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([3072, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.4.ffn.layers.0.0.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "size mismatch for backbone.stages.2.blocks.4.ffn.layers.1.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 3072]).\n",
      "size mismatch for backbone.stages.2.blocks.4.ffn.layers.1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.5.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.5.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table: copying a param with shape torch.Size([169, 12]) from checkpoint, the shape in current model is torch.Size([169, 24]).\n",
      "size mismatch for backbone.stages.2.blocks.5.attn.w_msa.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.5.attn.w_msa.qkv.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([2304]).\n",
      "size mismatch for backbone.stages.2.blocks.5.attn.w_msa.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.5.attn.w_msa.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.5.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.5.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.5.ffn.layers.0.0.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([3072, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.5.ffn.layers.0.0.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "size mismatch for backbone.stages.2.blocks.5.ffn.layers.1.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 3072]).\n",
      "size mismatch for backbone.stages.2.blocks.5.ffn.layers.1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.6.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.6.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.6.attn.w_msa.relative_position_bias_table: copying a param with shape torch.Size([169, 12]) from checkpoint, the shape in current model is torch.Size([169, 24]).\n",
      "size mismatch for backbone.stages.2.blocks.6.attn.w_msa.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.6.attn.w_msa.qkv.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([2304]).\n",
      "size mismatch for backbone.stages.2.blocks.6.attn.w_msa.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.6.attn.w_msa.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.6.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.6.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.6.ffn.layers.0.0.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([3072, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.6.ffn.layers.0.0.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "size mismatch for backbone.stages.2.blocks.6.ffn.layers.1.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 3072]).\n",
      "size mismatch for backbone.stages.2.blocks.6.ffn.layers.1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.7.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.7.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.7.attn.w_msa.relative_position_bias_table: copying a param with shape torch.Size([169, 12]) from checkpoint, the shape in current model is torch.Size([169, 24]).\n",
      "size mismatch for backbone.stages.2.blocks.7.attn.w_msa.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.7.attn.w_msa.qkv.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([2304]).\n",
      "size mismatch for backbone.stages.2.blocks.7.attn.w_msa.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.7.attn.w_msa.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.7.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.7.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.7.ffn.layers.0.0.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([3072, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.7.ffn.layers.0.0.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "size mismatch for backbone.stages.2.blocks.7.ffn.layers.1.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 3072]).\n",
      "size mismatch for backbone.stages.2.blocks.7.ffn.layers.1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.8.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.8.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.8.attn.w_msa.relative_position_bias_table: copying a param with shape torch.Size([169, 12]) from checkpoint, the shape in current model is torch.Size([169, 24]).\n",
      "size mismatch for backbone.stages.2.blocks.8.attn.w_msa.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.8.attn.w_msa.qkv.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([2304]).\n",
      "size mismatch for backbone.stages.2.blocks.8.attn.w_msa.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.8.attn.w_msa.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.8.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.8.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.8.ffn.layers.0.0.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([3072, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.8.ffn.layers.0.0.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "size mismatch for backbone.stages.2.blocks.8.ffn.layers.1.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 3072]).\n",
      "size mismatch for backbone.stages.2.blocks.8.ffn.layers.1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.9.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.9.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.9.attn.w_msa.relative_position_bias_table: copying a param with shape torch.Size([169, 12]) from checkpoint, the shape in current model is torch.Size([169, 24]).\n",
      "size mismatch for backbone.stages.2.blocks.9.attn.w_msa.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.9.attn.w_msa.qkv.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([2304]).\n",
      "size mismatch for backbone.stages.2.blocks.9.attn.w_msa.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.9.attn.w_msa.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.9.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.9.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.9.ffn.layers.0.0.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([3072, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.9.ffn.layers.0.0.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "size mismatch for backbone.stages.2.blocks.9.ffn.layers.1.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 3072]).\n",
      "size mismatch for backbone.stages.2.blocks.9.ffn.layers.1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.10.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.10.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.10.attn.w_msa.relative_position_bias_table: copying a param with shape torch.Size([169, 12]) from checkpoint, the shape in current model is torch.Size([169, 24]).\n",
      "size mismatch for backbone.stages.2.blocks.10.attn.w_msa.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.10.attn.w_msa.qkv.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([2304]).\n",
      "size mismatch for backbone.stages.2.blocks.10.attn.w_msa.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.10.attn.w_msa.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.10.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.10.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.10.ffn.layers.0.0.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([3072, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.10.ffn.layers.0.0.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "size mismatch for backbone.stages.2.blocks.10.ffn.layers.1.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 3072]).\n",
      "size mismatch for backbone.stages.2.blocks.10.ffn.layers.1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.11.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.11.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.11.attn.w_msa.relative_position_bias_table: copying a param with shape torch.Size([169, 12]) from checkpoint, the shape in current model is torch.Size([169, 24]).\n",
      "size mismatch for backbone.stages.2.blocks.11.attn.w_msa.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.11.attn.w_msa.qkv.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([2304]).\n",
      "size mismatch for backbone.stages.2.blocks.11.attn.w_msa.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.11.attn.w_msa.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.11.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.11.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.11.ffn.layers.0.0.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([3072, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.11.ffn.layers.0.0.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "size mismatch for backbone.stages.2.blocks.11.ffn.layers.1.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 3072]).\n",
      "size mismatch for backbone.stages.2.blocks.11.ffn.layers.1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.12.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.12.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.12.attn.w_msa.relative_position_bias_table: copying a param with shape torch.Size([169, 12]) from checkpoint, the shape in current model is torch.Size([169, 24]).\n",
      "size mismatch for backbone.stages.2.blocks.12.attn.w_msa.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.12.attn.w_msa.qkv.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([2304]).\n",
      "size mismatch for backbone.stages.2.blocks.12.attn.w_msa.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.12.attn.w_msa.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.12.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.12.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.12.ffn.layers.0.0.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([3072, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.12.ffn.layers.0.0.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "size mismatch for backbone.stages.2.blocks.12.ffn.layers.1.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 3072]).\n",
      "size mismatch for backbone.stages.2.blocks.12.ffn.layers.1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.13.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.13.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.13.attn.w_msa.relative_position_bias_table: copying a param with shape torch.Size([169, 12]) from checkpoint, the shape in current model is torch.Size([169, 24]).\n",
      "size mismatch for backbone.stages.2.blocks.13.attn.w_msa.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.13.attn.w_msa.qkv.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([2304]).\n",
      "size mismatch for backbone.stages.2.blocks.13.attn.w_msa.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.13.attn.w_msa.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.13.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.13.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.13.ffn.layers.0.0.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([3072, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.13.ffn.layers.0.0.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "size mismatch for backbone.stages.2.blocks.13.ffn.layers.1.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 3072]).\n",
      "size mismatch for backbone.stages.2.blocks.13.ffn.layers.1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.14.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.14.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.14.attn.w_msa.relative_position_bias_table: copying a param with shape torch.Size([169, 12]) from checkpoint, the shape in current model is torch.Size([169, 24]).\n",
      "size mismatch for backbone.stages.2.blocks.14.attn.w_msa.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.14.attn.w_msa.qkv.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([2304]).\n",
      "size mismatch for backbone.stages.2.blocks.14.attn.w_msa.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.14.attn.w_msa.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.14.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.14.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.14.ffn.layers.0.0.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([3072, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.14.ffn.layers.0.0.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "size mismatch for backbone.stages.2.blocks.14.ffn.layers.1.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 3072]).\n",
      "size mismatch for backbone.stages.2.blocks.14.ffn.layers.1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.15.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.15.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.15.attn.w_msa.relative_position_bias_table: copying a param with shape torch.Size([169, 12]) from checkpoint, the shape in current model is torch.Size([169, 24]).\n",
      "size mismatch for backbone.stages.2.blocks.15.attn.w_msa.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.15.attn.w_msa.qkv.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([2304]).\n",
      "size mismatch for backbone.stages.2.blocks.15.attn.w_msa.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.15.attn.w_msa.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.15.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.15.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.15.ffn.layers.0.0.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([3072, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.15.ffn.layers.0.0.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "size mismatch for backbone.stages.2.blocks.15.ffn.layers.1.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 3072]).\n",
      "size mismatch for backbone.stages.2.blocks.15.ffn.layers.1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.16.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.16.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.16.attn.w_msa.relative_position_bias_table: copying a param with shape torch.Size([169, 12]) from checkpoint, the shape in current model is torch.Size([169, 24]).\n",
      "size mismatch for backbone.stages.2.blocks.16.attn.w_msa.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.16.attn.w_msa.qkv.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([2304]).\n",
      "size mismatch for backbone.stages.2.blocks.16.attn.w_msa.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.16.attn.w_msa.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.16.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.16.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.16.ffn.layers.0.0.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([3072, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.16.ffn.layers.0.0.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "size mismatch for backbone.stages.2.blocks.16.ffn.layers.1.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 3072]).\n",
      "size mismatch for backbone.stages.2.blocks.16.ffn.layers.1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.17.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.17.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.17.attn.w_msa.relative_position_bias_table: copying a param with shape torch.Size([169, 12]) from checkpoint, the shape in current model is torch.Size([169, 24]).\n",
      "size mismatch for backbone.stages.2.blocks.17.attn.w_msa.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.17.attn.w_msa.qkv.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([2304]).\n",
      "size mismatch for backbone.stages.2.blocks.17.attn.w_msa.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.17.attn.w_msa.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.17.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.17.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.blocks.17.ffn.layers.0.0.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([3072, 768]).\n",
      "size mismatch for backbone.stages.2.blocks.17.ffn.layers.0.0.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "size mismatch for backbone.stages.2.blocks.17.ffn.layers.1.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 3072]).\n",
      "size mismatch for backbone.stages.2.blocks.17.ffn.layers.1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.stages.2.downsample.norm.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "size mismatch for backbone.stages.2.downsample.norm.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "size mismatch for backbone.stages.2.downsample.reduction.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([1536, 3072]).\n",
      "size mismatch for backbone.stages.3.blocks.0.norm1.weight: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "size mismatch for backbone.stages.3.blocks.0.norm1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "size mismatch for backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table: copying a param with shape torch.Size([169, 24]) from checkpoint, the shape in current model is torch.Size([169, 48]).\n",
      "size mismatch for backbone.stages.3.blocks.0.attn.w_msa.qkv.weight: copying a param with shape torch.Size([2304, 768]) from checkpoint, the shape in current model is torch.Size([4608, 1536]).\n",
      "size mismatch for backbone.stages.3.blocks.0.attn.w_msa.qkv.bias: copying a param with shape torch.Size([2304]) from checkpoint, the shape in current model is torch.Size([4608]).\n",
      "size mismatch for backbone.stages.3.blocks.0.attn.w_msa.proj.weight: copying a param with shape torch.Size([768, 768]) from checkpoint, the shape in current model is torch.Size([1536, 1536]).\n",
      "size mismatch for backbone.stages.3.blocks.0.attn.w_msa.proj.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "size mismatch for backbone.stages.3.blocks.0.norm2.weight: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "size mismatch for backbone.stages.3.blocks.0.norm2.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "size mismatch for backbone.stages.3.blocks.0.ffn.layers.0.0.weight: copying a param with shape torch.Size([3072, 768]) from checkpoint, the shape in current model is torch.Size([6144, 1536]).\n",
      "size mismatch for backbone.stages.3.blocks.0.ffn.layers.0.0.bias: copying a param with shape torch.Size([3072]) from checkpoint, the shape in current model is torch.Size([6144]).\n",
      "size mismatch for backbone.stages.3.blocks.0.ffn.layers.1.weight: copying a param with shape torch.Size([768, 3072]) from checkpoint, the shape in current model is torch.Size([1536, 6144]).\n",
      "size mismatch for backbone.stages.3.blocks.0.ffn.layers.1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "size mismatch for backbone.stages.3.blocks.1.norm1.weight: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "size mismatch for backbone.stages.3.blocks.1.norm1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "size mismatch for backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table: copying a param with shape torch.Size([169, 24]) from checkpoint, the shape in current model is torch.Size([169, 48]).\n",
      "size mismatch for backbone.stages.3.blocks.1.attn.w_msa.qkv.weight: copying a param with shape torch.Size([2304, 768]) from checkpoint, the shape in current model is torch.Size([4608, 1536]).\n",
      "size mismatch for backbone.stages.3.blocks.1.attn.w_msa.qkv.bias: copying a param with shape torch.Size([2304]) from checkpoint, the shape in current model is torch.Size([4608]).\n",
      "size mismatch for backbone.stages.3.blocks.1.attn.w_msa.proj.weight: copying a param with shape torch.Size([768, 768]) from checkpoint, the shape in current model is torch.Size([1536, 1536]).\n",
      "size mismatch for backbone.stages.3.blocks.1.attn.w_msa.proj.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "size mismatch for backbone.stages.3.blocks.1.norm2.weight: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "size mismatch for backbone.stages.3.blocks.1.norm2.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "size mismatch for backbone.stages.3.blocks.1.ffn.layers.0.0.weight: copying a param with shape torch.Size([3072, 768]) from checkpoint, the shape in current model is torch.Size([6144, 1536]).\n",
      "size mismatch for backbone.stages.3.blocks.1.ffn.layers.0.0.bias: copying a param with shape torch.Size([3072]) from checkpoint, the shape in current model is torch.Size([6144]).\n",
      "size mismatch for backbone.stages.3.blocks.1.ffn.layers.1.weight: copying a param with shape torch.Size([768, 3072]) from checkpoint, the shape in current model is torch.Size([1536, 6144]).\n",
      "size mismatch for backbone.stages.3.blocks.1.ffn.layers.1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "size mismatch for backbone.norm0.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.norm0.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "size mismatch for backbone.norm1.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.norm1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "size mismatch for backbone.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "size mismatch for backbone.norm3.weight: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "size mismatch for backbone.norm3.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "size mismatch for neck.lateral_convs.0.conv.weight: copying a param with shape torch.Size([256, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 192, 1, 1]).\n",
      "size mismatch for neck.lateral_convs.1.conv.weight: copying a param with shape torch.Size([256, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 384, 1, 1]).\n",
      "size mismatch for neck.lateral_convs.2.conv.weight: copying a param with shape torch.Size([256, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 768, 1, 1]).\n",
      "size mismatch for neck.lateral_convs.3.conv.weight: copying a param with shape torch.Size([256, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1536, 1, 1]).\n",
      "unexpected key in source state_dict: neck.extra_downsamples.0.0.conv.weight, neck.extra_downsamples.0.0.bn.weight, neck.extra_downsamples.0.0.bn.bias, neck.extra_downsamples.0.0.bn.running_mean, neck.extra_downsamples.0.0.bn.running_var, neck.extra_downsamples.0.0.bn.num_batches_tracked, neck.fpn_stages.0.gp_64_4.out_conv.conv.weight, neck.fpn_stages.0.gp_64_4.out_conv.conv.bias, neck.fpn_stages.0.gp_64_4.out_conv.bn.weight, neck.fpn_stages.0.gp_64_4.out_conv.bn.bias, neck.fpn_stages.0.gp_64_4.out_conv.bn.running_mean, neck.fpn_stages.0.gp_64_4.out_conv.bn.running_var, neck.fpn_stages.0.gp_64_4.out_conv.bn.num_batches_tracked, neck.fpn_stages.0.sum_44_4.out_conv.conv.weight, neck.fpn_stages.0.sum_44_4.out_conv.conv.bias, neck.fpn_stages.0.sum_44_4.out_conv.bn.weight, neck.fpn_stages.0.sum_44_4.out_conv.bn.bias, neck.fpn_stages.0.sum_44_4.out_conv.bn.running_mean, neck.fpn_stages.0.sum_44_4.out_conv.bn.running_var, neck.fpn_stages.0.sum_44_4.out_conv.bn.num_batches_tracked, neck.fpn_stages.0.sum_43_3.out_conv.conv.weight, neck.fpn_stages.0.sum_43_3.out_conv.conv.bias, neck.fpn_stages.0.sum_43_3.out_conv.bn.weight, neck.fpn_stages.0.sum_43_3.out_conv.bn.bias, neck.fpn_stages.0.sum_43_3.out_conv.bn.running_mean, neck.fpn_stages.0.sum_43_3.out_conv.bn.running_var, neck.fpn_stages.0.sum_43_3.out_conv.bn.num_batches_tracked, neck.fpn_stages.0.sum_34_4.out_conv.conv.weight, neck.fpn_stages.0.sum_34_4.out_conv.conv.bias, neck.fpn_stages.0.sum_34_4.out_conv.bn.weight, neck.fpn_stages.0.sum_34_4.out_conv.bn.bias, neck.fpn_stages.0.sum_34_4.out_conv.bn.running_mean, neck.fpn_stages.0.sum_34_4.out_conv.bn.running_var, neck.fpn_stages.0.sum_34_4.out_conv.bn.num_batches_tracked, neck.fpn_stages.0.sum_55_5.out_conv.conv.weight, neck.fpn_stages.0.sum_55_5.out_conv.conv.bias, neck.fpn_stages.0.sum_55_5.out_conv.bn.weight, neck.fpn_stages.0.sum_55_5.out_conv.bn.bias, neck.fpn_stages.0.sum_55_5.out_conv.bn.running_mean, neck.fpn_stages.0.sum_55_5.out_conv.bn.running_var, neck.fpn_stages.0.sum_55_5.out_conv.bn.num_batches_tracked, neck.fpn_stages.0.sum_77_7.out_conv.conv.weight, neck.fpn_stages.0.sum_77_7.out_conv.conv.bias, neck.fpn_stages.0.sum_77_7.out_conv.bn.weight, neck.fpn_stages.0.sum_77_7.out_conv.bn.bias, neck.fpn_stages.0.sum_77_7.out_conv.bn.running_mean, neck.fpn_stages.0.sum_77_7.out_conv.bn.running_var, neck.fpn_stages.0.sum_77_7.out_conv.bn.num_batches_tracked, neck.fpn_stages.0.gp_75_6.out_conv.conv.weight, neck.fpn_stages.0.gp_75_6.out_conv.conv.bias, neck.fpn_stages.0.gp_75_6.out_conv.bn.weight, neck.fpn_stages.0.gp_75_6.out_conv.bn.bias, neck.fpn_stages.0.gp_75_6.out_conv.bn.running_mean, neck.fpn_stages.0.gp_75_6.out_conv.bn.running_var, neck.fpn_stages.0.gp_75_6.out_conv.bn.num_batches_tracked, neck.fpn_stages.1.gp_64_4.out_conv.conv.weight, neck.fpn_stages.1.gp_64_4.out_conv.conv.bias, neck.fpn_stages.1.gp_64_4.out_conv.bn.weight, neck.fpn_stages.1.gp_64_4.out_conv.bn.bias, neck.fpn_stages.1.gp_64_4.out_conv.bn.running_mean, neck.fpn_stages.1.gp_64_4.out_conv.bn.running_var, neck.fpn_stages.1.gp_64_4.out_conv.bn.num_batches_tracked, neck.fpn_stages.1.sum_44_4.out_conv.conv.weight, neck.fpn_stages.1.sum_44_4.out_conv.conv.bias, neck.fpn_stages.1.sum_44_4.out_conv.bn.weight, neck.fpn_stages.1.sum_44_4.out_conv.bn.bias, neck.fpn_stages.1.sum_44_4.out_conv.bn.running_mean, neck.fpn_stages.1.sum_44_4.out_conv.bn.running_var, neck.fpn_stages.1.sum_44_4.out_conv.bn.num_batches_tracked, neck.fpn_stages.1.sum_43_3.out_conv.conv.weight, neck.fpn_stages.1.sum_43_3.out_conv.conv.bias, neck.fpn_stages.1.sum_43_3.out_conv.bn.weight, neck.fpn_stages.1.sum_43_3.out_conv.bn.bias, neck.fpn_stages.1.sum_43_3.out_conv.bn.running_mean, neck.fpn_stages.1.sum_43_3.out_conv.bn.running_var, neck.fpn_stages.1.sum_43_3.out_conv.bn.num_batches_tracked, neck.fpn_stages.1.sum_34_4.out_conv.conv.weight, neck.fpn_stages.1.sum_34_4.out_conv.conv.bias, neck.fpn_stages.1.sum_34_4.out_conv.bn.weight, neck.fpn_stages.1.sum_34_4.out_conv.bn.bias, neck.fpn_stages.1.sum_34_4.out_conv.bn.running_mean, neck.fpn_stages.1.sum_34_4.out_conv.bn.running_var, neck.fpn_stages.1.sum_34_4.out_conv.bn.num_batches_tracked, neck.fpn_stages.1.sum_55_5.out_conv.conv.weight, neck.fpn_stages.1.sum_55_5.out_conv.conv.bias, neck.fpn_stages.1.sum_55_5.out_conv.bn.weight, neck.fpn_stages.1.sum_55_5.out_conv.bn.bias, neck.fpn_stages.1.sum_55_5.out_conv.bn.running_mean, neck.fpn_stages.1.sum_55_5.out_conv.bn.running_var, neck.fpn_stages.1.sum_55_5.out_conv.bn.num_batches_tracked, neck.fpn_stages.1.sum_77_7.out_conv.conv.weight, neck.fpn_stages.1.sum_77_7.out_conv.conv.bias, neck.fpn_stages.1.sum_77_7.out_conv.bn.weight, neck.fpn_stages.1.sum_77_7.out_conv.bn.bias, neck.fpn_stages.1.sum_77_7.out_conv.bn.running_mean, neck.fpn_stages.1.sum_77_7.out_conv.bn.running_var, neck.fpn_stages.1.sum_77_7.out_conv.bn.num_batches_tracked, neck.fpn_stages.1.gp_75_6.out_conv.conv.weight, neck.fpn_stages.1.gp_75_6.out_conv.conv.bias, neck.fpn_stages.1.gp_75_6.out_conv.bn.weight, neck.fpn_stages.1.gp_75_6.out_conv.bn.bias, neck.fpn_stages.1.gp_75_6.out_conv.bn.running_mean, neck.fpn_stages.1.gp_75_6.out_conv.bn.running_var, neck.fpn_stages.1.gp_75_6.out_conv.bn.num_batches_tracked, neck.fpn_stages.2.gp_64_4.out_conv.conv.weight, neck.fpn_stages.2.gp_64_4.out_conv.conv.bias, neck.fpn_stages.2.gp_64_4.out_conv.bn.weight, neck.fpn_stages.2.gp_64_4.out_conv.bn.bias, neck.fpn_stages.2.gp_64_4.out_conv.bn.running_mean, neck.fpn_stages.2.gp_64_4.out_conv.bn.running_var, neck.fpn_stages.2.gp_64_4.out_conv.bn.num_batches_tracked, neck.fpn_stages.2.sum_44_4.out_conv.conv.weight, neck.fpn_stages.2.sum_44_4.out_conv.conv.bias, neck.fpn_stages.2.sum_44_4.out_conv.bn.weight, neck.fpn_stages.2.sum_44_4.out_conv.bn.bias, neck.fpn_stages.2.sum_44_4.out_conv.bn.running_mean, neck.fpn_stages.2.sum_44_4.out_conv.bn.running_var, neck.fpn_stages.2.sum_44_4.out_conv.bn.num_batches_tracked, neck.fpn_stages.2.sum_43_3.out_conv.conv.weight, neck.fpn_stages.2.sum_43_3.out_conv.conv.bias, neck.fpn_stages.2.sum_43_3.out_conv.bn.weight, neck.fpn_stages.2.sum_43_3.out_conv.bn.bias, neck.fpn_stages.2.sum_43_3.out_conv.bn.running_mean, neck.fpn_stages.2.sum_43_3.out_conv.bn.running_var, neck.fpn_stages.2.sum_43_3.out_conv.bn.num_batches_tracked, neck.fpn_stages.2.sum_34_4.out_conv.conv.weight, neck.fpn_stages.2.sum_34_4.out_conv.conv.bias, neck.fpn_stages.2.sum_34_4.out_conv.bn.weight, neck.fpn_stages.2.sum_34_4.out_conv.bn.bias, neck.fpn_stages.2.sum_34_4.out_conv.bn.running_mean, neck.fpn_stages.2.sum_34_4.out_conv.bn.running_var, neck.fpn_stages.2.sum_34_4.out_conv.bn.num_batches_tracked, neck.fpn_stages.2.sum_55_5.out_conv.conv.weight, neck.fpn_stages.2.sum_55_5.out_conv.conv.bias, neck.fpn_stages.2.sum_55_5.out_conv.bn.weight, neck.fpn_stages.2.sum_55_5.out_conv.bn.bias, neck.fpn_stages.2.sum_55_5.out_conv.bn.running_mean, neck.fpn_stages.2.sum_55_5.out_conv.bn.running_var, neck.fpn_stages.2.sum_55_5.out_conv.bn.num_batches_tracked, neck.fpn_stages.2.sum_77_7.out_conv.conv.weight, neck.fpn_stages.2.sum_77_7.out_conv.conv.bias, neck.fpn_stages.2.sum_77_7.out_conv.bn.weight, neck.fpn_stages.2.sum_77_7.out_conv.bn.bias, neck.fpn_stages.2.sum_77_7.out_conv.bn.running_mean, neck.fpn_stages.2.sum_77_7.out_conv.bn.running_var, neck.fpn_stages.2.sum_77_7.out_conv.bn.num_batches_tracked, neck.fpn_stages.2.gp_75_6.out_conv.conv.weight, neck.fpn_stages.2.gp_75_6.out_conv.conv.bias, neck.fpn_stages.2.gp_75_6.out_conv.bn.weight, neck.fpn_stages.2.gp_75_6.out_conv.bn.bias, neck.fpn_stages.2.gp_75_6.out_conv.bn.running_mean, neck.fpn_stages.2.gp_75_6.out_conv.bn.running_var, neck.fpn_stages.2.gp_75_6.out_conv.bn.num_batches_tracked, neck.fpn_stages.3.gp_64_4.out_conv.conv.weight, neck.fpn_stages.3.gp_64_4.out_conv.conv.bias, neck.fpn_stages.3.gp_64_4.out_conv.bn.weight, neck.fpn_stages.3.gp_64_4.out_conv.bn.bias, neck.fpn_stages.3.gp_64_4.out_conv.bn.running_mean, neck.fpn_stages.3.gp_64_4.out_conv.bn.running_var, neck.fpn_stages.3.gp_64_4.out_conv.bn.num_batches_tracked, neck.fpn_stages.3.sum_44_4.out_conv.conv.weight, neck.fpn_stages.3.sum_44_4.out_conv.conv.bias, neck.fpn_stages.3.sum_44_4.out_conv.bn.weight, neck.fpn_stages.3.sum_44_4.out_conv.bn.bias, neck.fpn_stages.3.sum_44_4.out_conv.bn.running_mean, neck.fpn_stages.3.sum_44_4.out_conv.bn.running_var, neck.fpn_stages.3.sum_44_4.out_conv.bn.num_batches_tracked, neck.fpn_stages.3.sum_43_3.out_conv.conv.weight, neck.fpn_stages.3.sum_43_3.out_conv.conv.bias, neck.fpn_stages.3.sum_43_3.out_conv.bn.weight, neck.fpn_stages.3.sum_43_3.out_conv.bn.bias, neck.fpn_stages.3.sum_43_3.out_conv.bn.running_mean, neck.fpn_stages.3.sum_43_3.out_conv.bn.running_var, neck.fpn_stages.3.sum_43_3.out_conv.bn.num_batches_tracked, neck.fpn_stages.3.sum_34_4.out_conv.conv.weight, neck.fpn_stages.3.sum_34_4.out_conv.conv.bias, neck.fpn_stages.3.sum_34_4.out_conv.bn.weight, neck.fpn_stages.3.sum_34_4.out_conv.bn.bias, neck.fpn_stages.3.sum_34_4.out_conv.bn.running_mean, neck.fpn_stages.3.sum_34_4.out_conv.bn.running_var, neck.fpn_stages.3.sum_34_4.out_conv.bn.num_batches_tracked, neck.fpn_stages.3.sum_55_5.out_conv.conv.weight, neck.fpn_stages.3.sum_55_5.out_conv.conv.bias, neck.fpn_stages.3.sum_55_5.out_conv.bn.weight, neck.fpn_stages.3.sum_55_5.out_conv.bn.bias, neck.fpn_stages.3.sum_55_5.out_conv.bn.running_mean, neck.fpn_stages.3.sum_55_5.out_conv.bn.running_var, neck.fpn_stages.3.sum_55_5.out_conv.bn.num_batches_tracked, neck.fpn_stages.3.sum_77_7.out_conv.conv.weight, neck.fpn_stages.3.sum_77_7.out_conv.conv.bias, neck.fpn_stages.3.sum_77_7.out_conv.bn.weight, neck.fpn_stages.3.sum_77_7.out_conv.bn.bias, neck.fpn_stages.3.sum_77_7.out_conv.bn.running_mean, neck.fpn_stages.3.sum_77_7.out_conv.bn.running_var, neck.fpn_stages.3.sum_77_7.out_conv.bn.num_batches_tracked, neck.fpn_stages.3.gp_75_6.out_conv.conv.weight, neck.fpn_stages.3.gp_75_6.out_conv.conv.bias, neck.fpn_stages.3.gp_75_6.out_conv.bn.weight, neck.fpn_stages.3.gp_75_6.out_conv.bn.bias, neck.fpn_stages.3.gp_75_6.out_conv.bn.running_mean, neck.fpn_stages.3.gp_75_6.out_conv.bn.running_var, neck.fpn_stages.3.gp_75_6.out_conv.bn.num_batches_tracked, neck.fpn_stages.4.gp_64_4.out_conv.conv.weight, neck.fpn_stages.4.gp_64_4.out_conv.conv.bias, neck.fpn_stages.4.gp_64_4.out_conv.bn.weight, neck.fpn_stages.4.gp_64_4.out_conv.bn.bias, neck.fpn_stages.4.gp_64_4.out_conv.bn.running_mean, neck.fpn_stages.4.gp_64_4.out_conv.bn.running_var, neck.fpn_stages.4.gp_64_4.out_conv.bn.num_batches_tracked, neck.fpn_stages.4.sum_44_4.out_conv.conv.weight, neck.fpn_stages.4.sum_44_4.out_conv.conv.bias, neck.fpn_stages.4.sum_44_4.out_conv.bn.weight, neck.fpn_stages.4.sum_44_4.out_conv.bn.bias, neck.fpn_stages.4.sum_44_4.out_conv.bn.running_mean, neck.fpn_stages.4.sum_44_4.out_conv.bn.running_var, neck.fpn_stages.4.sum_44_4.out_conv.bn.num_batches_tracked, neck.fpn_stages.4.sum_43_3.out_conv.conv.weight, neck.fpn_stages.4.sum_43_3.out_conv.conv.bias, neck.fpn_stages.4.sum_43_3.out_conv.bn.weight, neck.fpn_stages.4.sum_43_3.out_conv.bn.bias, neck.fpn_stages.4.sum_43_3.out_conv.bn.running_mean, neck.fpn_stages.4.sum_43_3.out_conv.bn.running_var, neck.fpn_stages.4.sum_43_3.out_conv.bn.num_batches_tracked, neck.fpn_stages.4.sum_34_4.out_conv.conv.weight, neck.fpn_stages.4.sum_34_4.out_conv.conv.bias, neck.fpn_stages.4.sum_34_4.out_conv.bn.weight, neck.fpn_stages.4.sum_34_4.out_conv.bn.bias, neck.fpn_stages.4.sum_34_4.out_conv.bn.running_mean, neck.fpn_stages.4.sum_34_4.out_conv.bn.running_var, neck.fpn_stages.4.sum_34_4.out_conv.bn.num_batches_tracked, neck.fpn_stages.4.sum_55_5.out_conv.conv.weight, neck.fpn_stages.4.sum_55_5.out_conv.conv.bias, neck.fpn_stages.4.sum_55_5.out_conv.bn.weight, neck.fpn_stages.4.sum_55_5.out_conv.bn.bias, neck.fpn_stages.4.sum_55_5.out_conv.bn.running_mean, neck.fpn_stages.4.sum_55_5.out_conv.bn.running_var, neck.fpn_stages.4.sum_55_5.out_conv.bn.num_batches_tracked, neck.fpn_stages.4.sum_77_7.out_conv.conv.weight, neck.fpn_stages.4.sum_77_7.out_conv.conv.bias, neck.fpn_stages.4.sum_77_7.out_conv.bn.weight, neck.fpn_stages.4.sum_77_7.out_conv.bn.bias, neck.fpn_stages.4.sum_77_7.out_conv.bn.running_mean, neck.fpn_stages.4.sum_77_7.out_conv.bn.running_var, neck.fpn_stages.4.sum_77_7.out_conv.bn.num_batches_tracked, neck.fpn_stages.4.gp_75_6.out_conv.conv.weight, neck.fpn_stages.4.gp_75_6.out_conv.conv.bias, neck.fpn_stages.4.gp_75_6.out_conv.bn.weight, neck.fpn_stages.4.gp_75_6.out_conv.bn.bias, neck.fpn_stages.4.gp_75_6.out_conv.bn.running_mean, neck.fpn_stages.4.gp_75_6.out_conv.bn.running_var, neck.fpn_stages.4.gp_75_6.out_conv.bn.num_batches_tracked, neck.fpn_stages.5.gp_64_4.out_conv.conv.weight, neck.fpn_stages.5.gp_64_4.out_conv.conv.bias, neck.fpn_stages.5.gp_64_4.out_conv.bn.weight, neck.fpn_stages.5.gp_64_4.out_conv.bn.bias, neck.fpn_stages.5.gp_64_4.out_conv.bn.running_mean, neck.fpn_stages.5.gp_64_4.out_conv.bn.running_var, neck.fpn_stages.5.gp_64_4.out_conv.bn.num_batches_tracked, neck.fpn_stages.5.sum_44_4.out_conv.conv.weight, neck.fpn_stages.5.sum_44_4.out_conv.conv.bias, neck.fpn_stages.5.sum_44_4.out_conv.bn.weight, neck.fpn_stages.5.sum_44_4.out_conv.bn.bias, neck.fpn_stages.5.sum_44_4.out_conv.bn.running_mean, neck.fpn_stages.5.sum_44_4.out_conv.bn.running_var, neck.fpn_stages.5.sum_44_4.out_conv.bn.num_batches_tracked, neck.fpn_stages.5.sum_43_3.out_conv.conv.weight, neck.fpn_stages.5.sum_43_3.out_conv.conv.bias, neck.fpn_stages.5.sum_43_3.out_conv.bn.weight, neck.fpn_stages.5.sum_43_3.out_conv.bn.bias, neck.fpn_stages.5.sum_43_3.out_conv.bn.running_mean, neck.fpn_stages.5.sum_43_3.out_conv.bn.running_var, neck.fpn_stages.5.sum_43_3.out_conv.bn.num_batches_tracked, neck.fpn_stages.5.sum_34_4.out_conv.conv.weight, neck.fpn_stages.5.sum_34_4.out_conv.conv.bias, neck.fpn_stages.5.sum_34_4.out_conv.bn.weight, neck.fpn_stages.5.sum_34_4.out_conv.bn.bias, neck.fpn_stages.5.sum_34_4.out_conv.bn.running_mean, neck.fpn_stages.5.sum_34_4.out_conv.bn.running_var, neck.fpn_stages.5.sum_34_4.out_conv.bn.num_batches_tracked, neck.fpn_stages.5.sum_55_5.out_conv.conv.weight, neck.fpn_stages.5.sum_55_5.out_conv.conv.bias, neck.fpn_stages.5.sum_55_5.out_conv.bn.weight, neck.fpn_stages.5.sum_55_5.out_conv.bn.bias, neck.fpn_stages.5.sum_55_5.out_conv.bn.running_mean, neck.fpn_stages.5.sum_55_5.out_conv.bn.running_var, neck.fpn_stages.5.sum_55_5.out_conv.bn.num_batches_tracked, neck.fpn_stages.5.sum_77_7.out_conv.conv.weight, neck.fpn_stages.5.sum_77_7.out_conv.conv.bias, neck.fpn_stages.5.sum_77_7.out_conv.bn.weight, neck.fpn_stages.5.sum_77_7.out_conv.bn.bias, neck.fpn_stages.5.sum_77_7.out_conv.bn.running_mean, neck.fpn_stages.5.sum_77_7.out_conv.bn.running_var, neck.fpn_stages.5.sum_77_7.out_conv.bn.num_batches_tracked, neck.fpn_stages.5.gp_75_6.out_conv.conv.weight, neck.fpn_stages.5.gp_75_6.out_conv.conv.bias, neck.fpn_stages.5.gp_75_6.out_conv.bn.weight, neck.fpn_stages.5.gp_75_6.out_conv.bn.bias, neck.fpn_stages.5.gp_75_6.out_conv.bn.running_mean, neck.fpn_stages.5.gp_75_6.out_conv.bn.running_var, neck.fpn_stages.5.gp_75_6.out_conv.bn.num_batches_tracked, neck.fpn_stages.6.gp_64_4.out_conv.conv.weight, neck.fpn_stages.6.gp_64_4.out_conv.conv.bias, neck.fpn_stages.6.gp_64_4.out_conv.bn.weight, neck.fpn_stages.6.gp_64_4.out_conv.bn.bias, neck.fpn_stages.6.gp_64_4.out_conv.bn.running_mean, neck.fpn_stages.6.gp_64_4.out_conv.bn.running_var, neck.fpn_stages.6.gp_64_4.out_conv.bn.num_batches_tracked, neck.fpn_stages.6.sum_44_4.out_conv.conv.weight, neck.fpn_stages.6.sum_44_4.out_conv.conv.bias, neck.fpn_stages.6.sum_44_4.out_conv.bn.weight, neck.fpn_stages.6.sum_44_4.out_conv.bn.bias, neck.fpn_stages.6.sum_44_4.out_conv.bn.running_mean, neck.fpn_stages.6.sum_44_4.out_conv.bn.running_var, neck.fpn_stages.6.sum_44_4.out_conv.bn.num_batches_tracked, neck.fpn_stages.6.sum_43_3.out_conv.conv.weight, neck.fpn_stages.6.sum_43_3.out_conv.conv.bias, neck.fpn_stages.6.sum_43_3.out_conv.bn.weight, neck.fpn_stages.6.sum_43_3.out_conv.bn.bias, neck.fpn_stages.6.sum_43_3.out_conv.bn.running_mean, neck.fpn_stages.6.sum_43_3.out_conv.bn.running_var, neck.fpn_stages.6.sum_43_3.out_conv.bn.num_batches_tracked, neck.fpn_stages.6.sum_34_4.out_conv.conv.weight, neck.fpn_stages.6.sum_34_4.out_conv.conv.bias, neck.fpn_stages.6.sum_34_4.out_conv.bn.weight, neck.fpn_stages.6.sum_34_4.out_conv.bn.bias, neck.fpn_stages.6.sum_34_4.out_conv.bn.running_mean, neck.fpn_stages.6.sum_34_4.out_conv.bn.running_var, neck.fpn_stages.6.sum_34_4.out_conv.bn.num_batches_tracked, neck.fpn_stages.6.sum_55_5.out_conv.conv.weight, neck.fpn_stages.6.sum_55_5.out_conv.conv.bias, neck.fpn_stages.6.sum_55_5.out_conv.bn.weight, neck.fpn_stages.6.sum_55_5.out_conv.bn.bias, neck.fpn_stages.6.sum_55_5.out_conv.bn.running_mean, neck.fpn_stages.6.sum_55_5.out_conv.bn.running_var, neck.fpn_stages.6.sum_55_5.out_conv.bn.num_batches_tracked, neck.fpn_stages.6.sum_77_7.out_conv.conv.weight, neck.fpn_stages.6.sum_77_7.out_conv.conv.bias, neck.fpn_stages.6.sum_77_7.out_conv.bn.weight, neck.fpn_stages.6.sum_77_7.out_conv.bn.bias, neck.fpn_stages.6.sum_77_7.out_conv.bn.running_mean, neck.fpn_stages.6.sum_77_7.out_conv.bn.running_var, neck.fpn_stages.6.sum_77_7.out_conv.bn.num_batches_tracked, neck.fpn_stages.6.gp_75_6.out_conv.conv.weight, neck.fpn_stages.6.gp_75_6.out_conv.conv.bias, neck.fpn_stages.6.gp_75_6.out_conv.bn.weight, neck.fpn_stages.6.gp_75_6.out_conv.bn.bias, neck.fpn_stages.6.gp_75_6.out_conv.bn.running_mean, neck.fpn_stages.6.gp_75_6.out_conv.bn.running_var, neck.fpn_stages.6.gp_75_6.out_conv.bn.num_batches_tracked, neck.lateral_convs.0.bn.weight, neck.lateral_convs.0.bn.bias, neck.lateral_convs.0.bn.running_mean, neck.lateral_convs.0.bn.running_var, neck.lateral_convs.0.bn.num_batches_tracked, neck.lateral_convs.1.bn.weight, neck.lateral_convs.1.bn.bias, neck.lateral_convs.1.bn.running_mean, neck.lateral_convs.1.bn.running_var, neck.lateral_convs.1.bn.num_batches_tracked, neck.lateral_convs.2.bn.weight, neck.lateral_convs.2.bn.bias, neck.lateral_convs.2.bn.running_mean, neck.lateral_convs.2.bn.running_var, neck.lateral_convs.2.bn.num_batches_tracked, neck.lateral_convs.3.bn.weight, neck.lateral_convs.3.bn.bias, neck.lateral_convs.3.bn.running_mean, neck.lateral_convs.3.bn.running_var, neck.lateral_convs.3.bn.num_batches_tracked, roi_head.bbox_head.fc_cls.weight, roi_head.bbox_head.fc_cls.bias, roi_head.bbox_head.fc_reg.weight, roi_head.bbox_head.fc_reg.bias, roi_head.bbox_head.shared_fcs.0.weight, roi_head.bbox_head.shared_fcs.0.bias, roi_head.bbox_head.shared_fcs.1.weight, roi_head.bbox_head.shared_fcs.1.bias\n",
      "\n",
      "missing keys in source state_dict: neck.lateral_convs.0.conv.bias, neck.lateral_convs.1.conv.bias, neck.lateral_convs.2.conv.bias, neck.lateral_convs.3.conv.bias, neck.fpn_convs.0.conv.weight, neck.fpn_convs.0.conv.bias, neck.fpn_convs.1.conv.weight, neck.fpn_convs.1.conv.bias, neck.fpn_convs.2.conv.weight, neck.fpn_convs.2.conv.bias, neck.fpn_convs.3.conv.weight, neck.fpn_convs.3.conv.bias, roi_head.bbox_head.0.fc_cls.weight, roi_head.bbox_head.0.fc_cls.bias, roi_head.bbox_head.0.fc_reg.weight, roi_head.bbox_head.0.fc_reg.bias, roi_head.bbox_head.0.shared_fcs.0.weight, roi_head.bbox_head.0.shared_fcs.0.bias, roi_head.bbox_head.0.shared_fcs.1.weight, roi_head.bbox_head.0.shared_fcs.1.bias, roi_head.bbox_head.1.fc_cls.weight, roi_head.bbox_head.1.fc_cls.bias, roi_head.bbox_head.1.fc_reg.weight, roi_head.bbox_head.1.fc_reg.bias, roi_head.bbox_head.1.shared_fcs.0.weight, roi_head.bbox_head.1.shared_fcs.0.bias, roi_head.bbox_head.1.shared_fcs.1.weight, roi_head.bbox_head.1.shared_fcs.1.bias, roi_head.bbox_head.2.fc_cls.weight, roi_head.bbox_head.2.fc_cls.bias, roi_head.bbox_head.2.fc_reg.weight, roi_head.bbox_head.2.fc_reg.bias, roi_head.bbox_head.2.shared_fcs.0.weight, roi_head.bbox_head.2.shared_fcs.0.bias, roi_head.bbox_head.2.shared_fcs.1.weight, roi_head.bbox_head.2.shared_fcs.1.bias\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# checkpoint path\n",
    "checkpoint_path = os.path.join(cfg.work_dir, f'{epoch}.pth')\n",
    "\n",
    "model = build_detector(cfg.model, test_cfg=cfg.get('test_cfg')) # build detector\n",
    "checkpoint = load_checkpoint(model, checkpoint_path, map_location='cpu') # ckpt load\n",
    "\n",
    "model.CLASSES = dataset.CLASSES\n",
    "model = MMDataParallel(model.cuda(), device_ids=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9f5c2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>                            ] 183/4871, 2.0 task/s, elapsed: 92s, ETA:  2363s"
     ]
    }
   ],
   "source": [
    "output = single_gpu_test(model, data_loader, show_score_thr=0.05) # output 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5672a0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12661/603933923.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mclass_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mprediction_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mimage_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadImgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetImgIds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgIds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output' is not defined"
     ]
    }
   ],
   "source": [
    "# submission 양식에 맞게 output 후처리\n",
    "prediction_strings = []\n",
    "file_names = []\n",
    "coco = COCO(cfg.data.test.ann_file)\n",
    "img_ids = coco.getImgIds()\n",
    "\n",
    "class_num = 10\n",
    "for i, out in enumerate(output):\n",
    "    prediction_string = ''\n",
    "    image_info = coco.loadImgs(coco.getImgIds(imgIds=i))[0]\n",
    "    for j in range(class_num):\n",
    "        for o in out[j]:\n",
    "            prediction_string += str(j) + ' ' + str(o[4]) + ' ' + str(o[0]) + ' ' + str(o[1]) + ' ' + str(\n",
    "                o[2]) + ' ' + str(o[3]) + ' '\n",
    "        \n",
    "    prediction_strings.append(prediction_string)\n",
    "    file_names.append(image_info['file_name'])\n",
    "    \n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['PredictionString'] = prediction_strings\n",
    "submission['image_id'] = file_names\n",
    "submission.to_csv(os.path.join(cfg.work_dir, f'submission_{epoch}.csv'), index=None)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c0b1be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 ('detection')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "b94c6de4bce9a87a354a5fa9998691adc0532adddb9d4140f5ba941d00b01fae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
